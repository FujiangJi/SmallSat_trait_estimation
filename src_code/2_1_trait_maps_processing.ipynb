{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cfc94d3",
   "metadata": {},
   "source": [
    "### 1. Convert to Geotiff, reprojection, clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac18b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal\n",
    "data_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/1_HR_trait_maps/\"\n",
    "out_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/2_reprojection_trait_maps/\"\n",
    "filenames = os.listdir(data_path)\n",
    "filenames = [x for x in filenames if \".aux.xml\" not in x and \".hdr\" not in x]\n",
    "\n",
    "for file in filenames:\n",
    "    in_file = f\"{data_path}{file}\"\n",
    "    out_file = f\"{out_path}{file}.tif\"\n",
    "    \n",
    "    input_ds = gdal.Open(in_file)\n",
    "    output_ds = gdal.Warp(out_file, input_ds, dstSRS='EPSG:32611', format='GTiff')\n",
    "    \n",
    "\n",
    "# in_file = \"/130TB_raid0/fujiang/SmallSat_part2/1_imagery_data/SHIFT_RFL_20220420_vnir.tif\"\n",
    "# out_file = \"/130TB_raid0/fujiang/SmallSat_part2/1_imagery_data/SHIFT_RFL_20220420_vnir_reprojection.tif\"\n",
    "\n",
    "# input_ds = gdal.Open(in_file)\n",
    "# output_ds = gdal.Warp(out_file, input_ds, dstSRS='EPSG:32611', format='GTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ba3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal,gdalconst\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/2_reprojection_trait_maps/\"\n",
    "out_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/3_clipped_trait_maps/\"\n",
    "ul_x_new, lr_y_new, lr_x_new, ul_y_new = 174714.77272756316, 3816019.5146135557, 193347.5743273191, 3843232.8023862587\n",
    "\n",
    "filenames = os.listdir(data_path)\n",
    "filenames = [x for x in filenames if \".aux.xml\" not in x]\n",
    "for file in filenames:\n",
    "    in_file = f\"{data_path}{file}\"\n",
    "    out_file = f\"{out_path}{file[:-4]}_clipped.tif\"   \n",
    "    gdal.Warp(out_file, in_file, xRes=5, yRes=5, outputBounds=(ul_x_new, lr_y_new, lr_x_new, ul_y_new), cropToCutline=True, format='GTiff',resampleAlg=gdalconst.GRA_Bilinear)\n",
    "  \n",
    "# in_file = \"/130TB_raid0/fujiang/SmallSat_part2/1_imagery_data/SHIFT_RFL_20220420_vnir_reprojection.tif\"\n",
    "# out_file = \"/130TB_raid0/fujiang/SmallSat_part2/1_imagery_data/SHIFT_RFL_20220420_vnir_reprojection_clipped.tif\" \n",
    "# gdal.Warp(out_file, in_file, xRes=5, yRes=5, outputBounds=(ul_x_new, lr_y_new, lr_x_new, ul_y_new), cropToCutline=True, format='GTiff',resampleAlg=gdalconst.GRA_Bilinear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91992649",
   "metadata": {},
   "source": [
    "### 2. Upscale trait maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d614ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal,gdalconst\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_tif(tif_file):\n",
    "    dataset = gdal.Open(tif_file)\n",
    "    cols = dataset.RasterXSize\n",
    "    rows = dataset.RasterYSize\n",
    "    im_proj = (dataset.GetProjection())\n",
    "    im_Geotrans = (dataset.GetGeoTransform())\n",
    "    im_data = dataset.ReadAsArray(0, 0, cols, rows)\n",
    "    if im_data.ndim == 3:\n",
    "        im_data = np.moveaxis(dataset.ReadAsArray(0, 0, cols, rows), 0, -1)\n",
    "    return im_data, im_Geotrans, im_proj,rows, cols\n",
    "\n",
    "def array_to_geotiff(array, output_path, geo_transform, projection, band_names=None):\n",
    "    rows, cols, num_bands = array.shape\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dataset = driver.Create(output_path, cols, rows, num_bands, gdal.GDT_Float32)\n",
    "    \n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    \n",
    "    for band_num in range(num_bands):\n",
    "        band = dataset.GetRasterBand(band_num + 1)\n",
    "        band.WriteArray(array[:, :, band_num])\n",
    "        band.FlushCache()\n",
    "        \n",
    "        if band_names:\n",
    "            band.SetDescription(band_names[band_num])\n",
    "    dataset = None\n",
    "    band = None\n",
    "    return\n",
    "\n",
    "planet = \"/130TB_RAID0/fujiang/SmallSat_part2/1_imagery_data/PlanetScope_RFL_20230422_clipped_resampled.tif\"\n",
    "planet_data, planet_Geotrans, planet_proj,_, _ = read_tif(planet)\n",
    "\n",
    "nir_band = planet_data[:,:, 7]\n",
    "red_band = planet_data[:,:, 5]\n",
    "ndvi = (nir_band - red_band)/(nir_band + red_band)\n",
    "condition1 = ndvi > 0.3\n",
    "condition2 = nir_band>0.1\n",
    "mask1 = np.where(condition1, 1, np.nan)\n",
    "mask2 = np.where(condition2, 1, np.nan)\n",
    "mask = mask1 * mask2\n",
    "mask = np.expand_dims(mask, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65522b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/3_clipped_trait_maps/\"\n",
    "out_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/4_upscaling_trait_maps/\"\n",
    "\n",
    "filenames = os.listdir(data_path)\n",
    "filenames = [x for x in filenames if \".aux.xml\" not in x]\n",
    "\n",
    "for idx, file in enumerate(filenames):\n",
    "    trait_file = f\"{data_path}{file}\"\n",
    "    trait_array, trait_Geotrans, trait_proj, rows, cols =  read_tif(trait_file)\n",
    "    if (file == '20220420_d15N_clipped.tif')|(file == '20220420_d13C_clipped.tif'):\n",
    "        trait_array[trait_array<-100] = np.nan\n",
    "    else:\n",
    "        trait_array[trait_array<0] = np.nan\n",
    "        \n",
    "    masked_trait_map = mask * trait_array\n",
    "    \n",
    "    aggregated_traits = np.zeros(shape = ((rows//12)+1, (cols//12)+1, masked_trait_map.shape[2]))\n",
    "    veg_fraction = np.zeros(shape = ((rows//12)+1, (cols//12)+1, mask.shape[2]))\n",
    "    \n",
    "    for ii in range(0, rows, 12):\n",
    "        for jj in range(0, cols, 12):\n",
    "            data_array = masked_trait_map[ii: min(rows, (ii + 12)), jj: min(cols, (jj + 12)),:]\n",
    "            mean_values = np.nanmean(data_array, axis = (0,1))\n",
    "            aggregated_traits[int(ii/12), int(jj/12), :] = mean_values\n",
    "\n",
    "            data_array2 = mask[ii: min(rows, (ii + 12)), jj: min(cols, (jj + 12)),:]\n",
    "            one_counts = np.count_nonzero(data_array2 == 1)\n",
    "            fraction = one_counts/144\n",
    "            veg_fraction[int(ii/12), int(jj/12),:] = fraction\n",
    "    \n",
    "    output_path = f\"{out_path}/{file[:-4]}_60m.tif\"\n",
    "    mask_path = f\"{out_path}/0_20220420_vegetation_fraction.tif\"\n",
    "    \n",
    "    geo_transform = (trait_Geotrans[0], 60.0, trait_Geotrans[2],\n",
    "                     trait_Geotrans[3],trait_Geotrans[4],-60.0)\n",
    "\n",
    "    array_to_geotiff(aggregated_traits, output_path, geo_transform, trait_proj, band_names = [\"mean\", \"uncertainty\"])\n",
    "    if idx ==0:\n",
    "        array_to_geotiff(veg_fraction, mask_path, geo_transform, trait_proj, band_names = [\"mask\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1083f846",
   "metadata": {},
   "source": [
    "## 3. Extract training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439db8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal,gdalconst\n",
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def raster_to_points(geotiff, shp_name):\n",
    "    inDs = gdal.Open(geotiff)\n",
    "    DsoutDs = gdal.Translate(f\"{shp_name}.xyz\", inDs, format='XYZ', creationOptions=[\"ADD_HEADER_LINE=YES\"])\n",
    "    outDs = None\n",
    "    try:\n",
    "        os.remove(f'{shp_name}.csv')\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    os.rename(f'{shp_name}.xyz', f'{shp_name}.csv')\n",
    "    os.system('ogr2ogr -f \"ESRI Shapefile\" -oo X_POSSIBLE_NAMES=X* -oo Y_POSSIBLE_NAMES=Y* -oo KEEP_GEOM_COLUMNS=NO {0}.shp {0}.csv'.format(shp_name))\n",
    "    try:\n",
    "        os.remove(f'{shp_name}.csv')\n",
    "    except OSError:\n",
    "        pass\n",
    "    crs_wkt = inDs.GetProjection()\n",
    "    shp_layer = gpd.read_file(f\"{shp_name}.shp\")\n",
    "    shp_layer.crs = crs_wkt\n",
    "    shp_layer.to_file(f\"{shp_name}.shp\")\n",
    "    return\n",
    "\n",
    "def filter_points(gdf, min_distance):\n",
    "    gdf_copy = gdf.copy()\n",
    "    to_remove = []\n",
    "\n",
    "    for index, row in gdf_copy.iterrows():\n",
    "        if index not in to_remove:\n",
    "            distances = gdf_copy.geometry.distance(row.geometry)\n",
    "            close_points = distances[distances < min_distance].index.tolist()\n",
    "            close_points.remove(index)\n",
    "            to_remove.extend(close_points)\n",
    "\n",
    "    gdf_copy.drop(index=to_remove, inplace=True)\n",
    "    gdf_copy.reset_index(drop = True, inplace = True)\n",
    "    return gdf_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to points shapefile\n",
    "data = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/4_upscaling_trait_maps/0_20220420_vegetation_fraction.tif\"\n",
    "out_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/5_extract_training_samples/\"\n",
    "raster_to_points(data, f\"{out_path}1_extracted_points\")\n",
    "# 60 distance to avoid spatial autocorelation\n",
    "points = gpd.read_file(\"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/5_extract_training_samples/1_extracted_points.shp\")\n",
    "filtered_points = filter_points(points, 100)\n",
    "filtered_points.to_file(\"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/5_extract_training_samples/2_extracted_points_filter.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract trait values\n",
    "point_path = '/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/5_extract_training_samples/'\n",
    "points_files = [\"2_extracted_points_filter.shp\", \"2_extracted_points_filter_train.shp\", \"2_extracted_points_filter_test.shp\"]\n",
    "out_name = [\"3_extracted_points.csv\", \"3_extracted_points_train.csv\", \"3_extracted_points_test.csv\"]\n",
    "\n",
    "HR_image_path = \"/130TB_RAID0/fujiang/SmallSat_part2/1_imagery_data/1_fused_imagery/\"\n",
    "HR_image = \"/130TB_RAID0/fujiang/SmallSat_part2/1_imagery_data/PlanetScope_RFL_20230422_clipped_resampled.tif\"\n",
    "LR_image = \"/130TB_RAID0/fujiang/SmallSat_part2/1_imagery_data/EMIT_L2A_RFL_20230422_clipped_resampled.tif\"\n",
    "\n",
    "HR_traits = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/3_clipped_trait_maps/\"\n",
    "upscaled_traits = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/4_upscaling_trait_maps/\"\n",
    "out_path = \"/130TB_RAID0/fujiang/SmallSat_part2/2_high_resolution_trait_maps/5_extract_training_samples/\"\n",
    "\n",
    "filenames1 = os.listdir(HR_traits)\n",
    "filenames1 = [x for x in filenames1 if \".aux.xml\" not in x]\n",
    "\n",
    "filenames2 = os.listdir(upscaled_traits)\n",
    "filenames2 = [x for x in filenames2 if \".aux.xml\" not in x and \"vegetation_fraction\" not in x]\n",
    "\n",
    "traits = ['LWC_area', 'magnesium', 'd15N', 'phosphorus', 'Manganese_ppm', 'hemicellulose', 'cellulose', 'd13C', 'chl_area', 'phenolics_mg_g', 'LWC', \n",
    "          'sugars_mg_g', 'Phenolics_DS', 'Sugars_DS', 'potassium', 'sulfur', 'NSC_DS', 'nitrogen', 'lignin', 'LMA', 'Aluminum_ppm', '%C', 'calcium']\n",
    "\n",
    "sub_traits = ['LWC_area', 'magnesium', 'phosphorus', 'Manganese_ppm', 'hemicellulose', 'cellulose', 'chl_area', 'phenolics_mg_g', 'LWC', 'sugars_mg_g',\n",
    "              'Phenolics_DS', 'Sugars_DS', 'potassium', 'sulfur', 'NSC_DS', 'nitrogen', 'lignin', 'LMA', 'Aluminum_ppm', '%C', 'calcium']\n",
    "\n",
    "for idx, points_file in enumerate(points_files):\n",
    "    print(f\"***********************{points_file}***********************\")\n",
    "    points = gpd.read_file(f\"{point_path}{points_file}\")\n",
    "    points[\"vege_frac\"] = points[\"Z\"].astype(float)\n",
    "    points.drop(columns=['Z'],inplace = True)\n",
    "    points.reset_index(drop = True, inplace = True)\n",
    "    # **********************************************Extract HR_traits**********************************************\n",
    "    print(\"Start extract the high resolution trait values\")\n",
    "    for file in filenames1:\n",
    "        in_tif = f\"{HR_traits}{file}\"\n",
    "        tiff_ds = gdal.Open(in_tif)\n",
    "        \n",
    "        band = tiff_ds.GetRasterBand(1)\n",
    "        extracted_values = []\n",
    "        for index, row in points.iterrows():\n",
    "            point = row.geometry\n",
    "            x, y = point.x, point.y\n",
    "            px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "            py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values.append(value)\n",
    "        \n",
    "        splits = file.split(\"_\")[1:-1]\n",
    "        aa = (\"_\").join(splits)\n",
    "        col_name = f\"HR_{aa}\"\n",
    "        \n",
    "        points[col_name] = extracted_values\n",
    "\n",
    "    \n",
    "    filter_cols = [f\"HR_{x}\" for x in sub_traits]\n",
    "    points = points[~((points[filter_cols] < 0) | (points[filter_cols].isna())).any(axis=1)]\n",
    "    points.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # **********************************************Extract upscaled_traits**********************************************\n",
    "    print(\"Start extract the upscaled trait values\")\n",
    "    for file in filenames2:\n",
    "        in_tif = f\"{upscaled_traits}{file}\"\n",
    "        tiff_ds = gdal.Open(in_tif)\n",
    "        \n",
    "        band = tiff_ds.GetRasterBand(1)\n",
    "        extracted_values = []\n",
    "        for index, row in points.iterrows():\n",
    "            point = row.geometry\n",
    "            x, y = point.x, point.y\n",
    "            px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "            py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values.append(value)\n",
    "\n",
    "        splits = file.split(\"_\")[1:-2]\n",
    "        aa = (\"_\").join(splits)\n",
    "        col_name = f\"upscaled_{aa}\"\n",
    "        points[col_name] = extracted_values\n",
    "    \n",
    "    filter_cols = [f\"upscaled_{x}\" for x in sub_traits]    \n",
    "    points = points[~((points[filter_cols] < 0) | (points[filter_cols].isna())).any(axis=1)]\n",
    "    points.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # **********************************************Extract EMIT_reflectance**********************************************\n",
    "    print(\"Start extract the reflectance of EMIT imagery\")\n",
    "    tiff_ds = gdal.Open(LR_image)\n",
    "    num_bands = tiff_ds.RasterCount\n",
    "\n",
    "    extracted_values = [[] for _ in range(num_bands)]\n",
    "    for index, row in points.iterrows():\n",
    "        point = row.geometry\n",
    "        x, y = point.x, point.y\n",
    "        \n",
    "        px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "        py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "        \n",
    "        for band_num in range(1, num_bands + 1):\n",
    "            band = tiff_ds.GetRasterBand(band_num)\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values[band_num - 1].append(value)\n",
    "\n",
    "    extracted_values = pd.DataFrame(np.array(extracted_values)).T\n",
    "    extracted_values.columns = [f\"EMIT_{x}_nm\" for x in np.arange(400, 2401, 10)]\n",
    "    points = pd.concat([points, extracted_values], axis = 1)\n",
    "    \n",
    "    # **********************************************Extract Planet_reflectance**********************************************\n",
    "    print(\"Start extract the reflectance of PlanetScope imagery\")\n",
    "    tiff_ds = gdal.Open(HR_image)\n",
    "    num_bands = tiff_ds.RasterCount\n",
    "\n",
    "    extracted_values = [[] for _ in range(num_bands)]\n",
    "    for index, row in points.iterrows():\n",
    "        point = row.geometry\n",
    "        x, y = point.x, point.y\n",
    "        \n",
    "        px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "        py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "        \n",
    "        for band_num in range(1, num_bands + 1):\n",
    "            band = tiff_ds.GetRasterBand(band_num)\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values[band_num - 1].append(value)\n",
    "\n",
    "    extracted_values = pd.DataFrame(np.array(extracted_values)).T\n",
    "    extracted_values.columns = [f\"Planet_{x}_nm\" for x in [443, 490, 531, 565, 610, 665, 705, 865]]\n",
    "    points = pd.concat([points, extracted_values], axis = 1)\n",
    "\n",
    "    # **********************************************Extract fused_image_reflectance**********************************************\n",
    "    print(\"Start extract the reflectance of fused images\")\n",
    "    filenames = os.listdir(HR_image_path)\n",
    "    filenames = [x for x in filenames if \".aux.xml\" not in x]\n",
    "\n",
    "    start_var = True\n",
    "    for file in filenames:\n",
    "        model = file.split(\"_\")[0]\n",
    "        if model == \"Fusion3\":\n",
    "            model = \"MSHFNET\"\n",
    "        elif model == \"Fusion5\":\n",
    "            model = \"MSAHFNET\"\n",
    "        print(f\"   -{model}\")\n",
    "            \n",
    "        tiff_ds = gdal.Open(f\"{HR_image_path}{file}\")\n",
    "        num_bands = tiff_ds.RasterCount\n",
    "        \n",
    "        extracted_values = [[] for _ in range(num_bands)]\n",
    "        for index, row in points.iterrows():\n",
    "            point = row.geometry\n",
    "            x, y = point.x, point.y\n",
    "            \n",
    "            px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "            py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "            \n",
    "            for band_num in range(1, num_bands + 1):\n",
    "                band = tiff_ds.GetRasterBand(band_num)\n",
    "                arr = band.ReadAsArray(px, py, 1, 1)\n",
    "                if arr is not None:\n",
    "                    value = arr[0][0]\n",
    "                else:\n",
    "                    value = np.nan\n",
    "                extracted_values[band_num - 1].append(value)\n",
    "\n",
    "        extracted_values = pd.DataFrame(np.array(extracted_values)).T\n",
    "        extracted_values.columns = [f\"{model}_model_{x}_nm\" for x in np.arange(400, 2401, 10)]\n",
    "        if start_var:\n",
    "            fused_refl = extracted_values\n",
    "            start_var = False\n",
    "        else:\n",
    "            fused_refl = pd.concat([fused_refl, extracted_values], axis = 1)\n",
    "\n",
    "    fused_refl.reset_index(drop = True, inplace = True)\n",
    "    points = pd.concat([points, fused_refl], axis =1)\n",
    "    points = points[~points.filter(like=\"_model_\").isna().all(axis=1)]\n",
    "\n",
    "    saved_points = points.copy()\n",
    "    saved_points.drop(columns = [\"geometry\"],inplace = True)\n",
    "    saved_points.to_csv(f'{out_path}{out_name[idx]}',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
